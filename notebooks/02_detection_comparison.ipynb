{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Detection Backend Comparison\n",
        "\n",
        "This notebook compares different face detection backends available in FaceVerify.\n",
        "\n",
        "## Table of Contents\n",
        "1. Available Backends\n",
        "2. Detection Speed Comparison\n",
        "3. Detection Accuracy Comparison\n",
        "4. Visualization\n",
        "5. Recommendations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from faceverify import FaceVerifier\n",
        "from faceverify.config import VerifierConfig\n",
        "from faceverify.detection import FaceDetector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Available Backends\n",
        "\n",
        "FaceVerify supports multiple face detection backends:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List available detection backends\n",
        "BACKENDS = [\n",
        "    \"opencv\",      # OpenCV Haar Cascade (fastest, least accurate)\n",
        "    \"mtcnn\",       # Multi-task CNN (balanced)\n",
        "    \"retinaface\", # RetinaFace (most accurate, slower)\n",
        "    \"mediapipe\"    # MediaPipe (fast, good accuracy)\n",
        "]\n",
        "\n",
        "print(\"Available Face Detection Backends\")\n",
        "print(\"=\" * 50)\n",
        "for i, backend in enumerate(BACKENDS, 1):\n",
        "    print(f\"{i}. {backend}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check which backends are actually available\n",
        "detector = FaceDetector()\n",
        "available = detector.get_available_backends()\n",
        "\n",
        "print(\"\\nInstalled backends on this system:\")\n",
        "for backend in available:\n",
        "    print(f\"  [OK] {backend}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Detection Speed Comparison\n",
        "\n",
        "Measure detection speed for each backend:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test image path\n",
        "TEST_IMAGE = \"../test_images/person1_a.jpg\"\n",
        "\n",
        "# Load image once\n",
        "image = cv2.imread(TEST_IMAGE)\n",
        "if image is None:\n",
        "    print(f\"Error: Could not load {TEST_IMAGE}\")\n",
        "    print(\"Please update TEST_IMAGE path to a valid image.\")\n",
        "else:\n",
        "    print(f\"Loaded image: {image.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def benchmark_backend(backend_name, image_path, num_runs=5):\n",
        "    \"\"\"Benchmark a detection backend.\"\"\"\n",
        "    try:\n",
        "        config = VerifierConfig(detector_backend=backend_name)\n",
        "        verifier = FaceVerifier(config=config)\n",
        "        \n",
        "        times = []\n",
        "        for _ in range(num_runs):\n",
        "            start = time.time()\n",
        "            faces = verifier.detect_faces(image_path)\n",
        "            elapsed = time.time() - start\n",
        "            times.append(elapsed)\n",
        "        \n",
        "        avg_time = np.mean(times)\n",
        "        std_time = np.std(times)\n",
        "        num_faces = len(faces) if faces else 0\n",
        "        \n",
        "        return {\n",
        "            \"backend\": backend_name,\n",
        "            \"avg_time\": avg_time,\n",
        "            \"std_time\": std_time,\n",
        "            \"faces_detected\": num_faces,\n",
        "            \"status\": \"OK\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"backend\": backend_name,\n",
        "            \"avg_time\": 0,\n",
        "            \"std_time\": 0,\n",
        "            \"faces_detected\": 0,\n",
        "            \"status\": f\"Error: {str(e)[:50]}\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run benchmarks\n",
        "print(\"Running benchmarks (this may take a minute)...\")\n",
        "print()\n",
        "\n",
        "results = []\n",
        "for backend in BACKENDS:\n",
        "    print(f\"Testing {backend}...\", end=\" \")\n",
        "    result = benchmark_backend(backend, TEST_IMAGE)\n",
        "    results.append(result)\n",
        "    if result[\"status\"] == \"OK\":\n",
        "        print(f\"Done ({result['avg_time']:.3f}s)\")\n",
        "    else:\n",
        "        print(result[\"status\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display results table\n",
        "print(\"\\nBenchmark Results\")\n",
        "print(\"=\" * 70)\n",
        "print(f\"{'Backend':<15} {'Avg Time':<12} {'Std Dev':<12} {'Faces':<8} {'Status'}\")\n",
        "print(\"-\" * 70)\n",
        "\n",
        "for r in results:\n",
        "    if r[\"status\"] == \"OK\":\n",
        "        print(f\"{r['backend']:<15} {r['avg_time']:.4f}s      {r['std_time']:.4f}s      {r['faces_detected']:<8} {r['status']}\")\n",
        "    else:\n",
        "        print(f\"{r['backend']:<15} {'N/A':<12} {'N/A':<12} {'N/A':<8} {r['status']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Detection Accuracy Comparison\n",
        "\n",
        "Compare bounding box accuracy across backends:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_detection_details(backend_name, image_path):\n",
        "    \"\"\"Get detailed detection information.\"\"\"\n",
        "    try:\n",
        "        config = VerifierConfig(detector_backend=backend_name)\n",
        "        verifier = FaceVerifier(config=config)\n",
        "        faces = verifier.detect_faces(image_path)\n",
        "        return faces\n",
        "    except Exception as e:\n",
        "        print(f\"Error with {backend_name}: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get detections from each backend\n",
        "all_detections = {}\n",
        "for backend in BACKENDS:\n",
        "    faces = get_detection_details(backend, TEST_IMAGE)\n",
        "    all_detections[backend] = faces\n",
        "    print(f\"{backend}: {len(faces)} face(s) detected\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Visualization\n",
        "\n",
        "Visualize detection results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def draw_detections(image, faces, backend_name, color):\n",
        "    \"\"\"Draw bounding boxes on image.\"\"\"\n",
        "    img_copy = image.copy()\n",
        "    \n",
        "    for face in faces:\n",
        "        if hasattr(face, 'bbox'):\n",
        "            x, y, w, h = face.bbox\n",
        "        elif isinstance(face, dict) and 'bbox' in face:\n",
        "            x, y, w, h = face['bbox']\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "        cv2.rectangle(img_copy, (int(x), int(y)), (int(x+w), int(y+h)), color, 2)\n",
        "        cv2.putText(img_copy, backend_name, (int(x), int(y)-10), \n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
        "    \n",
        "    return img_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create comparison visualization\n",
        "if image is not None:\n",
        "    colors = [\n",
        "        (255, 0, 0),    # Blue for opencv\n",
        "        (0, 255, 0),    # Green for mtcnn\n",
        "        (0, 0, 255),    # Red for retinaface\n",
        "        (255, 255, 0)   # Cyan for mediapipe\n",
        "    ]\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 12))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for idx, (backend, color) in enumerate(zip(BACKENDS, colors)):\n",
        "        faces = all_detections.get(backend, [])\n",
        "        img_with_boxes = draw_detections(image, faces, backend, color)\n",
        "        img_rgb = cv2.cvtColor(img_with_boxes, cv2.COLOR_BGR2RGB)\n",
        "        \n",
        "        axes[idx].imshow(img_rgb)\n",
        "        axes[idx].set_title(f\"{backend} ({len(faces)} faces)\")\n",
        "        axes[idx].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"detection_comparison.png\", dpi=150)\n",
        "    plt.show()\n",
        "    print(\"Saved comparison to detection_comparison.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Recommendations\n",
        "\n",
        "Based on the benchmarks, here are recommendations for different use cases:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "recommendations = \"\"\"\n",
        "BACKEND RECOMMENDATIONS\n",
        "=======================\n",
        "\n",
        "1. REAL-TIME APPLICATIONS (webcam, video)\n",
        "   Recommended: opencv or mediapipe\n",
        "   Reason: Fastest detection speed\n",
        "\n",
        "2. HIGH ACCURACY REQUIRED (security, verification)\n",
        "   Recommended: retinaface\n",
        "   Reason: Most accurate bounding boxes and landmarks\n",
        "\n",
        "3. BALANCED (general purpose)\n",
        "   Recommended: mtcnn\n",
        "   Reason: Good balance of speed and accuracy\n",
        "\n",
        "4. RESOURCE CONSTRAINED (embedded, mobile)\n",
        "   Recommended: opencv\n",
        "   Reason: Lowest memory and CPU usage\n",
        "\n",
        "5. MULTIPLE FACES IN IMAGE\n",
        "   Recommended: mtcnn or retinaface\n",
        "   Reason: Better at detecting multiple faces\n",
        "\"\"\"\n",
        "\n",
        "print(recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary table\n",
        "summary = \"\"\"\n",
        "SUMMARY TABLE\n",
        "=============\n",
        "\n",
        "| Backend    | Speed    | Accuracy | Multi-face | GPU Support |\n",
        "|------------|----------|----------|------------|-------------|\n",
        "| opencv     | Fast     | Low      | Fair       | No          |\n",
        "| mtcnn      | Medium   | High     | Good       | Yes         |\n",
        "| retinaface | Slow     | Highest  | Excellent  | Yes         |\n",
        "| mediapipe  | Fast     | Medium   | Good       | Yes         |\n",
        "\"\"\"\n",
        "\n",
        "print(summary)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "\n",
        "Continue to `03_embedding_analysis.ipynb` to learn about face embedding models."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
