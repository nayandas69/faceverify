{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Face Embedding Analysis\n",
        "\n",
        "This notebook analyzes face embeddings and compares different embedding models.\n",
        "\n",
        "## Table of Contents\n",
        "1. Understanding Embeddings\n",
        "2. Extracting Embeddings\n",
        "3. Embedding Visualization\n",
        "4. Similarity Metrics\n",
        "5. Model Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from faceverify import FaceVerifier\n",
        "from faceverify.config import VerifierConfig\n",
        "from faceverify.embedding import EmbeddingGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Understanding Embeddings\n",
        "\n",
        "Face embeddings are numerical representations of faces in high-dimensional space.\n",
        "\n",
        "Key concepts:\n",
        "- Each face is converted to a vector (e.g., 512 dimensions for Facenet512)\n",
        "- Similar faces have similar vectors (close in space)\n",
        "- Different faces have different vectors (far apart in space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Available embedding models\n",
        "EMBEDDING_MODELS = [\n",
        "    \"facenet\",      # 128-dimensional embeddings\n",
        "    \"facenet512\",   # 512-dimensional embeddings (recommended)\n",
        "    \"arcface\",      # 512-dimensional, state-of-the-art\n",
        "    \"vggface\"       # VGGFace model\n",
        "]\n",
        "\n",
        "print(\"Available Embedding Models\")\n",
        "print(\"=\" * 40)\n",
        "for model in EMBEDDING_MODELS:\n",
        "    print(f\"  - {model}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Extracting Embeddings\n",
        "\n",
        "Extract face embeddings from images:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test images\n",
        "IMAGES = {\n",
        "    \"person1_a\": \"../test_images/person1_a.jpg\",\n",
        "    \"person1_b\": \"../test_images/person1_b.jpg\",\n",
        "    \"person2\": \"../test_images/person2.jpg\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize verifier\n",
        "verifier = FaceVerifier()\n",
        "\n",
        "# Extract embeddings for each image\n",
        "embeddings = {}\n",
        "\n",
        "for name, path in IMAGES.items():\n",
        "    try:\n",
        "        emb = verifier.extract_embedding(path)\n",
        "        embeddings[name] = emb\n",
        "        print(f\"{name}: embedding shape = {emb.shape}\")\n",
        "    except Exception as e:\n",
        "        print(f\"{name}: Error - {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Examine embedding statistics\n",
        "print(\"\\nEmbedding Statistics\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "for name, emb in embeddings.items():\n",
        "    print(f\"\\n{name}:\")\n",
        "    print(f\"  Dimensions: {len(emb)}\")\n",
        "    print(f\"  Min value:  {emb.min():.4f}\")\n",
        "    print(f\"  Max value:  {emb.max():.4f}\")\n",
        "    print(f\"  Mean:       {emb.mean():.4f}\")\n",
        "    print(f\"  Std:        {emb.std():.4f}\")\n",
        "    print(f\"  L2 Norm:    {np.linalg.norm(emb):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Embedding Visualization\n",
        "\n",
        "Visualize embeddings using dimensionality reduction:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create embedding matrix\n",
        "if len(embeddings) >= 2:\n",
        "    names = list(embeddings.keys())\n",
        "    emb_matrix = np.array([embeddings[n] for n in names])\n",
        "    \n",
        "    print(f\"Embedding matrix shape: {emb_matrix.shape}\")\n",
        "else:\n",
        "    print(\"Need at least 2 embeddings for visualization\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize embedding distribution\n",
        "if len(embeddings) >= 1:\n",
        "    fig, axes = plt.subplots(1, len(embeddings), figsize=(5*len(embeddings), 4))\n",
        "    \n",
        "    if len(embeddings) == 1:\n",
        "        axes = [axes]\n",
        "    \n",
        "    for idx, (name, emb) in enumerate(embeddings.items()):\n",
        "        axes[idx].hist(emb, bins=50, alpha=0.7, color='steelblue')\n",
        "        axes[idx].set_title(f\"{name}\")\n",
        "        axes[idx].set_xlabel(\"Value\")\n",
        "        axes[idx].set_ylabel(\"Frequency\")\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"embedding_distributions.png\", dpi=150)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PCA visualization (if we have enough samples)\n",
        "if len(embeddings) >= 3:\n",
        "    pca = PCA(n_components=2)\n",
        "    emb_2d = pca.fit_transform(emb_matrix)\n",
        "    \n",
        "    plt.figure(figsize=(8, 6))\n",
        "    \n",
        "    # Color by person\n",
        "    colors = ['blue', 'blue', 'red']  # person1_a, person1_b are same person\n",
        "    \n",
        "    for i, (name, color) in enumerate(zip(names, colors)):\n",
        "        plt.scatter(emb_2d[i, 0], emb_2d[i, 1], c=color, s=100, label=name)\n",
        "        plt.annotate(name, (emb_2d[i, 0], emb_2d[i, 1]), fontsize=10)\n",
        "    \n",
        "    plt.title(\"Face Embeddings (PCA Projection)\")\n",
        "    plt.xlabel(f\"PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)\")\n",
        "    plt.ylabel(f\"PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)\")\n",
        "    plt.legend()\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.savefig(\"embedding_pca.png\", dpi=150)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Similarity Metrics\n",
        "\n",
        "Compare different similarity/distance metrics:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy.spatial.distance import cosine, euclidean\n",
        "\n",
        "def compute_similarities(emb1, emb2):\n",
        "    \"\"\"Compute various similarity metrics.\"\"\"\n",
        "    results = {}\n",
        "    \n",
        "    # Cosine similarity (1 - cosine distance)\n",
        "    results['cosine_similarity'] = 1 - cosine(emb1, emb2)\n",
        "    \n",
        "    # Euclidean distance\n",
        "    results['euclidean_distance'] = euclidean(emb1, emb2)\n",
        "    \n",
        "    # Normalized Euclidean (on unit vectors)\n",
        "    emb1_norm = emb1 / np.linalg.norm(emb1)\n",
        "    emb2_norm = emb2 / np.linalg.norm(emb2)\n",
        "    results['normalized_euclidean'] = euclidean(emb1_norm, emb2_norm)\n",
        "    \n",
        "    # Dot product\n",
        "    results['dot_product'] = np.dot(emb1_norm, emb2_norm)\n",
        "    \n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all pairs\n",
        "if len(embeddings) >= 2:\n",
        "    print(\"Similarity Analysis\")\n",
        "    print(\"=\" * 60)\n",
        "    \n",
        "    pairs = [\n",
        "        (\"person1_a\", \"person1_b\", \"Same person\"),\n",
        "        (\"person1_a\", \"person2\", \"Different people\"),\n",
        "    ]\n",
        "    \n",
        "    for name1, name2, description in pairs:\n",
        "        if name1 in embeddings and name2 in embeddings:\n",
        "            sims = compute_similarities(embeddings[name1], embeddings[name2])\n",
        "            \n",
        "            print(f\"\\n{name1} vs {name2} ({description})\")\n",
        "            print(\"-\" * 40)\n",
        "            for metric, value in sims.items():\n",
        "                print(f\"  {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize similarity matrix\n",
        "if len(embeddings) >= 2:\n",
        "    names = list(embeddings.keys())\n",
        "    n = len(names)\n",
        "    \n",
        "    # Compute cosine similarity matrix\n",
        "    sim_matrix = np.zeros((n, n))\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            sim_matrix[i, j] = 1 - cosine(embeddings[names[i]], embeddings[names[j]])\n",
        "    \n",
        "    # Plot heatmap\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(sim_matrix, cmap='RdYlGn', vmin=0, vmax=1)\n",
        "    plt.colorbar(label='Cosine Similarity')\n",
        "    \n",
        "    plt.xticks(range(n), names, rotation=45, ha='right')\n",
        "    plt.yticks(range(n), names)\n",
        "    \n",
        "    # Add values\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            plt.text(j, i, f'{sim_matrix[i,j]:.2f}', ha='center', va='center', fontsize=12)\n",
        "    \n",
        "    plt.title('Face Similarity Matrix')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"similarity_matrix.png\", dpi=150)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Model Comparison\n",
        "\n",
        "Compare embeddings from different models:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_model(model_name, image_path):\n",
        "    \"\"\"Test embedding extraction with specific model.\"\"\"\n",
        "    try:\n",
        "        config = VerifierConfig(embedding_model=model_name)\n",
        "        verifier = FaceVerifier(config=config)\n",
        "        emb = verifier.extract_embedding(image_path)\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"dimensions\": len(emb),\n",
        "            \"status\": \"OK\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"model\": model_name,\n",
        "            \"dimensions\": 0,\n",
        "            \"status\": f\"Error: {str(e)[:40]}\"\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test each model\n",
        "test_image = list(IMAGES.values())[0]\n",
        "\n",
        "print(\"Embedding Model Comparison\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"{'Model':<15} {'Dimensions':<15} {'Status'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "for model in EMBEDDING_MODELS:\n",
        "    result = test_model(model, test_image)\n",
        "    print(f\"{result['model']:<15} {result['dimensions']:<15} {result['status']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Key takeaways:\n",
        "\n",
        "1. Face embeddings are high-dimensional vectors representing faces\n",
        "2. Cosine similarity is commonly used to compare face embeddings\n",
        "3. Same person = high similarity (above 0.65), different person = low similarity\n",
        "4. Facenet512 provides 512-dimensional embeddings with good accuracy\n",
        "5. The embedding distribution can help identify quality issues\n",
        "\n",
        "Next, see `04_threshold_tuning.ipynb` to learn about optimal threshold selection."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
